sources:
  fluentbit:
    type: socket
    address: 0.0.0.0:24224
    mode: tcp

transforms:
  metrics_processing:
    type: remap
    inputs:
      - fluentbit
    source: |
      # Ensure .tag is a string
      .tag, err = to_string(.tag)
      if err != null {
        log("Failed to convert .tag to string", level: "warn")
        .tag = ""
      }

      # Filter metrics
      if starts_with(.tag, "metrics.") {
        .host, err = to_string(.host)
        if err != null {
          log("Failed to convert .host to string", level: "warn")
          .host = "unknown"
        }
        .service = "system"
        .metric_name = replace(.tag, "metrics.", "")

        # Validation of .message
        if .message == null {
          log("Missing .message in metrics event", level: "warn")
          .metric_value = 0.0
          .timestamp = now()
          .tags = {}
        } else {
          message_str, err = to_string(.message)
          if err != null {
            log("Failed to convert .message to string", level: "warn")
            message_str = "{}"
          }
          parsed, err = parse_json(message_str)
          if err != null {
            log("Failed to parse JSON in metrics event: " + to_string(err), level: "warn")
            .metric_value = 0.0
            .timestamp = now()
            .tags = {}
          } else {
            # Handle specific metric types based on .metric_name
            .metric_value = if .metric_name == "cpu" {
              to_float(parsed.cpu_p) ?? 0.0
            } else if .metric_name == "mem" {
              to_float(parsed."Mem.used") ?? 0.0
            } else if .metric_name == "disk" {
              to_float(parsed.write_size) ?? 0.0
            } else {
              0.0
            }

            # Safely handle timestamp conversion
            date_ms = if parsed.date != null {
              to_float(parsed.date) * 1000
            } else {
              to_float(now())
            }
            .timestamp = from_unix_timestamp(to_int(date_ms) ?? to_int(now())) ?? now()

            # Extract tags
            .tags = if parsed.cpu0 != null {
              {"cpu_core": "0", "p_user": to_string(parsed.cpu0.p_user) ?? "", "p_system": to_string(parsed.cpu0.p_system) ?? ""}
            } else {
              {}
            }
          }
        }
      } else {
        null
      }

  logs_processing:
    type: remap
    inputs:
      - fluentbit
    source: |
      # Ensure .tag is a string
      .tag, err = to_string(.tag)
      if err != null {
        log("Failed to convert .tag to string", level: "warn")
        .tag = ""
      }

      # Filter logs
      if starts_with(.tag, "logs.") {
        .host, err = to_string(.host)
        if err != null {
          log("Failed to convert .host to string", level: "warn")
          .host = "unknown"
        }
        .service = "app"
        .tag = replace(.tag, "logs.", "")

        # Validation of .message
        if .message == null {
          log("Missing .message in logs event", level: "warn")
          .timestamp = now()
          .level = "unknown"
          .message = ""
          .tags = {}
        } else {
          message_str, err = to_string(.message)
          if err != null {
            log("Failed to convert .message to string", level: "warn")
            message_str = "[]"
          }
          parsed, err = parse_json(message_str)
          if err != null {
            log("Failed to parse JSON in logs event: " + to_string(err), level: "warn")
            .timestamp = now()
            .level = "unknown"
            .message = message_str
            .tags = {}
          } else {
            # Handle array of log entries
            if is_array(parsed) {
              # Process each log entry
              for_each(parsed) -> |index, entry| {
                # Create a new event by modifying the current event
                .timestamp = if entry.date != null {
                  date_ms = to_float(entry.date) * 1000
                  from_unix_timestamp(to_int(date_ms) ?? to_int(now())) ?? now()
                } else {
                  now()
                }
                .level = to_string(entry.level) ?? "unknown"
                .message = to_string(entry.log) ?? ""
                .tags = if entry.tags != null { entry.tags } else { {} }
                # Output the event (implicitly handled by VRL)
              }
              null
            } else {
              # Single log entry
              .timestamp = if parsed.date != null {
                date_ms = to_float(parsed.date) * 1000
                from_unix_timestamp(to_int(date_ms) ?? to_int(now())) ?? now()
              } else {
                now()
              }
              .level = to_string(parsed.level) ?? "unknown"
              .message = to_string(parsed.log) ?? ""
              .tags = if parsed.tags != null { parsed.tags } else { {} }
            }
          }
        }
      } else {
        null
      }

sinks:
  metrics_clickhouse:
    type: clickhouse
    inputs:
      - metrics_processing
    endpoint: http://89.116.38.238:8123
    database: default
    table: metrics_log
    compression: gzip
    skip_unknown_fields: true
    date_time_best_effort: true
    buffer:
      type: memory
      max_events: 1000
      when_full: block
    encoding:
      only_fields:
        - timestamp
        - host
        - service
        - metric_name
        - metric_value
        - tags

  logs_clickhouse:
    type: clickhouse
    inputs:
      - logs_processing
    endpoint: http://89.116.38.238:8123
    database: default
    table: logs_text
    compression: gzip
    skip_unknown_fields: true
    date_time_best_effort: true
    buffer:
      type: memory
      max_events: 1000
      when_full: block
    encoding:
      only_fields:
        - timestamp
        - host
        - service
        - level
        - message
        - tags