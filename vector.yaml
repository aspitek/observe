sources:
  fluentbit:
    type: socket
    address: 0.0.0.0:24224
    mode: tcp
    format: fluent

transforms:
  metrics_processing:
    type: remap
    inputs:
      - fluentbit
    source: |
      # Journaliser l'entrée pour le débogage
      log("Received event: " + to_string(.),  level: "debug")
      
      # Vérifier que le tag existe et le convertir en string
      if exists(.tag) {
        .tag = to_string(.tag) ?? "unknown"
      } else {
        .tag = "unknown"
      }
      
      # Filtrer les métriques - moins restrictif
      if !contains(.tag, "metrics") {
        log("Dropping non-metrics event with tag: " + .tag, level: "debug")
        null
      } else {
        # Extraire le nom de la métrique depuis le tag
        .metric_name = if contains(.tag, "cpu") {
          "cpu"
        } else if contains(.tag, "mem") {
          "mem"
        } else if contains(.tag, "disk") {
          "disk"
        } else {
          replace(.tag, "metrics.", "")
        }
        
        # Définir les champs par défaut
        .host = to_string(.host) ?? "unknown"
        .service = "system"
        
        # Traiter le message selon le format observé
        if exists(.message) {
          message = .message
          
          # Vérifier si le message est un tableau
          if is_array(message) {
            log("Message is an array, extracting first element", level: "debug")
            message = message[0]
          }
          
          # Convertir en string si nécessaire
          if !is_string(message) {
            message_str = to_string(message) ?? "{}"
          } else {
            message_str = message
          }
          
          # Essayer d'analyser le JSON
          parsed, err = parse_json(message_str)
          if err != null {
            log("Failed parsing JSON: " + to_string(err), level: "warn")
            parsed = {}
          }
          
          # Extraire les valeurs selon le type de métrique
          if .metric_name == "cpu" {
            if exists(parsed.cpu_p) {
              .metric_value = to_float(parsed.cpu_p) ?? 0.0
              .tags = {
                "user_p": to_string(parsed.user_p) ?? "0",
                "system_p": to_string(parsed.system_p) ?? "0"
              }
            } else {
              .metric_value = 0.0
              .tags = {}
            }
          } else if .metric_name == "mem" {
            if exists(parsed."Mem.used") {
              .metric_value = to_float(parsed."Mem.used") ?? 0.0
              .tags = {
                "total": to_string(parsed."Mem.total") ?? "0"
              }
            } else {
              .metric_value = 0.0
              .tags = {}
            }
          } else if .metric_name == "disk" {
            if exists(parsed.write_size) {
              .metric_value = to_float(parsed.write_size) ?? 0.0
              .tags = {}
            } else {
              .metric_value = 0.0
              .tags = {}
            }
          } else {
            # Métrique inconnue
            .metric_value = 0.0
            .tags = {}
          }
          
          # Gestion du timestamp
          if exists(parsed.date) {
            date_val = to_float(parsed.date)
            date_ms = date_val * 1000
            .timestamp, err = from_unix_timestamp(to_int(date_ms))
            if err != null {
              .timestamp = now()
            }
          } else {
            .timestamp = now()
          }
        } else {
          # Aucun message trouvé
          .metric_value = 0.0
          .tags = {}
          .timestamp = now()
        }
        
        # Journaliser le résultat final pour le débogage
        log("Processed metric event: " + to_string(.), level: "debug")
      }

  logs_processing:
    type: remap
    inputs:
      - fluentbit
    source: |
      # Journaliser l'entrée pour le débogage
      log("Received log event: " + to_string(.),  level: "debug")
      
      # Vérifier que le tag existe et le convertir en string
      if exists(.tag) {
        .tag = to_string(.tag) ?? "unknown"
      } else {
        .tag = "unknown"
      }
      
      # Filtrer les logs - moins restrictif
      if !contains(.tag, "logs") {
        log("Dropping non-log event with tag: " + .tag, level: "debug")
        null
      } else {
        # Définir les champs par défaut
        .host = to_string(.host) ?? "unknown"
        .service = "app"
        .level = "info"  # Niveau par défaut
        
        # Traiter le message selon le format observé
        if exists(.message) {
          message = .message
          
          # Vérifier si le message est un tableau
          if is_array(message) {
            log("Log message is an array, extracting first element", level: "debug")
            message = message[0]
          }
          
          # Convertir en string si nécessaire
          if !is_string(message) {
            message_str = to_string(message) ?? "{}"
          } else {
            message_str = message
          }
          
          # Essayer d'analyser le JSON
          parsed, err = parse_json(message_str)
          if err != null {
            # Si ce n'est pas du JSON, utiliser le message tel quel
            log("Log is not JSON, using raw message", level: "debug")
            .message = message_str
            .timestamp = now()
            .tags = {}
          } else {
            # Extraire les informations pertinentes
            if exists(parsed.log) {
              .message = to_string(parsed.log)
            } else {
              .message = message_str
            }
            
            # Extraire le niveau si présent
            if exists(parsed.level) {
              .level = to_string(parsed.level)
            }
            
            # Extraire les tags si présents
            if exists(parsed.tags) {
              .tags = parsed.tags
            } else {
              .tags = {}
            }
            
            # Gestion du timestamp
            if exists(parsed.date) {
              date_val = to_float(parsed.date)
              date_ms = date_val * 1000
              .timestamp, err = from_unix_timestamp(to_int(date_ms))
              if err != null {
                .timestamp = now()
              }
            } else {
              .timestamp = now()
            }
          }
        } else {
          # Aucun message trouvé
          .message = "Empty log message"
          .tags = {}
          .timestamp = now()
        }
        
        # Journaliser le résultat final pour le débogage
        log("Processed log event: " + to_string(.), level: "debug")
      }

sinks:
  metrics_clickhouse:
    type: clickhouse
    inputs:
      - metrics_processing
    endpoint: http://89.116.38.238:8123
    database: default
    table: metrics_log
    compression: gzip
    skip_unknown_fields: true
    date_time_best_effort: true
    buffer:
      type: memory
      max_events: 100
      when_full: drop_newest
    batch:
      max_events: 5
      timeout_secs: 0.2
    encoding:
      only_fields:
        - timestamp
        - host
        - service
        - metric_name
        - metric_value
        - tags
    request:
      timeout_secs: 3
      retry_attempts: 5

  logs_clickhouse:
    type: clickhouse
    inputs:
      - logs_processing
    endpoint: http://89.116.38.238:8123
    database: default
    table: logs_text
    compression: gzip
    skip_unknown_fields: true
    date_time_best_effort: true
    buffer:
      type: memory
      max_events: 100
      when_full: drop_newest
    batch:
      max_events: 5
      timeout_secs: 0.2
    encoding:
      only_fields:
        - timestamp
        - host
        - service
        - level
        - message
        - tags
    request:
      timeout_secs: 3
      retry_attempts: 5

  debug_console:
    type: console
    inputs:
      - metrics_processing
      - logs_processing
    encoding:
      codec: json